{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25a48d2-6503-420d-ab88-c77546c38cef",
   "metadata": {},
   "source": [
    "# Ingesting with LLamaindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fb9a9-e8f1-4bcf-9441-c1f9b668da1c",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In the lesson, we'll continue exploring how llamaindex can help us with the data ingestion stage.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf6b92-542e-4af6-9f3f-495bc2bf7957",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dee090-b7e4-4214-9ab2-76a539abbaf5",
   "metadata": {},
   "source": [
    "If you look at the index.py file, you'll see that instead of using `pymupdf` to read in our documents, we use llamaindex's SimpleDirectoryReader.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105e9c5-93cf-4c89-ad66-c3e8c539cc3a",
   "metadata": {},
   "source": [
    "```python\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=\"./data/10k\",\n",
    "    required_exts=[\".pdf\"])\n",
    "\n",
    "documents = reader.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae250b6-debd-43f0-b248-ec14ff478e5e",
   "metadata": {},
   "source": [
    "By calling `reader.load_data()` this directly returns a list of document objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0012d59-020b-4e6a-b548-d256edbec1a0",
   "metadata": {},
   "source": [
    "The `SimpleDirectoryReader` takes various arguments for loading files from a directory.  So above, we we specified the input directory and extension type (pdf) to select our documents.  But we can also specify specific input files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac5fe1-5c50-4585-868c-aa15ad445395",
   "metadata": {},
   "source": [
    "```python\n",
    "lyft_docs = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    ").load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86160a47-e76a-4572-85d5-8f9b05117af8",
   "metadata": {},
   "source": [
    "Either way, this will return a list of documents, which we can directly create an index from these documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fee94-c9e6-41ce-b71e-a42b5c6040ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e888a-783b-4e6b-85c4-bafc77c9d1fe",
   "metadata": {},
   "source": [
    "And this one function will parse our documents into nodes (chunks), embed those nodes, and create a database, and index the nodes.\n",
    "\n",
    "From there, we can create a query engine and ask questions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09fd227-81f8-4100-a237-64a55c480aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = index.as_query_engine(similarity_top_k=3)\n",
    "response = query_engine.query(\"What is this document about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847714b-e95d-4243-948e-c2c01daa7df9",
   "metadata": {},
   "source": [
    "That's it!  So we can see the benefit of using a library like llamaindex.  With it we can build a rag pipeline in just a few lines of code.  Yet, we also have the option to customize our pipeline along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11680fc5-ddde-421e-af56-a0051d8c3326",
   "metadata": {},
   "source": [
    "### More connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc4f29-e69f-4da6-9863-4e8cf3594887",
   "metadata": {},
   "source": [
    "Above, the SimpleDirectoryReader is an example of a connector.  A connector is what reads in data and returns `Documents` with the `load_data` function.  LLamaindex has many different connectors.  \n",
    "\n",
    "For example, this how we can create a GoogleDocs connector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1eb8b3-5081-4702-a72c-2943587a51af",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from llama_index.readers.google import GoogleDocsReader\n",
    "\n",
    "loader = GoogleDocsReader()\n",
    "documents = loader.load_data(document_ids=[...])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a16262-5aa9-4963-9ad0-e0052ab5a253",
   "metadata": {},
   "source": [
    "> You can learn more about this [here](https://docs.llamaindex.ai/en/stable/examples/data_connectors/GoogleDocsDemo.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701078f-c7c6-43fa-bc3c-fbc10cb569c6",
   "metadata": {},
   "source": [
    "And this is a connector for reading webpages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b5b87-fcf6-4734-bab7-257e232a5f95",
   "metadata": {},
   "source": [
    "```python\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"http://paulgraham.com/worked.html\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a52ca-8c9c-4634-86f6-8afe0991987b",
   "metadata": {},
   "source": [
    "> You can see more [here](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6452766-149e-4495-a65a-fad4d0ae1b21",
   "metadata": {},
   "source": [
    "Notice again, that all of our connectors follow the same pattern.  We create the connector `SimpleWebPageReader()`, and then we call `load_data()` to return a list of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000c806-12fd-44ca-94bf-551a5dbb7fbd",
   "metadata": {},
   "source": [
    "From there, we can parse the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02113cd2-8cca-4591-9f18-0f7ec65593bf",
   "metadata": {},
   "source": [
    "```python\n",
    "parser = SentenceSplitter(chunk_size=1024)\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69916778-2bb1-48b5-9295-0131441890ee",
   "metadata": {},
   "source": [
    "Create embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e12099f-7d42-43ae-bae0-75bfd41393c6",
   "metadata": {},
   "source": [
    "```python\n",
    "for node in nodes:\n",
    "        node_embedding = embed_model.get_text_embedding(\n",
    "            node.get_content()\n",
    "        )\n",
    "        node.embedding = node_embedding\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea0d8a-1559-4007-abf9-5051e71e73b5",
   "metadata": {},
   "source": [
    "And store the data in a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556359c-af97-489d-a536-8e5f0674518e",
   "metadata": {},
   "source": [
    "```python\n",
    "index = VectorStoreIndex(nodes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601df09-5da6-44a0-a16e-43a67e1e7234",
   "metadata": {},
   "source": [
    "Or we just directly pass the documents into our VectorStoreIndex, and will perform this procedure under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b921563-6bc7-4924-aac5-915572d713dc",
   "metadata": {},
   "source": [
    "```python\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "response = query_engine.query(\"What is this document about?\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5aa5e-d1fc-4821-a3db-bf01aca5788a",
   "metadata": {},
   "source": [
    "### Wrapping Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8050b1-2773-4210-8859-c6bd0934b2b8",
   "metadata": {},
   "source": [
    "Curious about what connectors are available?  You can check out [llamahub.ai](https://llamahub.ai/) to explore more, or if you ask ChatGPT here are some of the answers it gave:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3115652-6e75-4ddd-b141-dbde44b016e1",
   "metadata": {},
   "source": [
    "* NotionPageReader\n",
    "* GoogleDocsReader\n",
    "* SlackReader\n",
    "* SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e95de-7cb9-4d79-a8f8-5e8c58a7c559",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[HTML Reader Connector](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da833e2b-ba2e-493f-b82c-bcf4d4ecc590",
   "metadata": {},
   "source": [
    "[10k tutorial](https://docs.llamaindex.ai/en/stable/examples/usecases/10k_sub_question.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd2cebf-c602-483d-8e44-452674fd44d2",
   "metadata": {},
   "source": [
    "[Custom Connectors](https://www.gettingstarted.ai/llamaindex-data-connectors-create-custom-chatgpt-using-own-documents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab205cc6-9d03-4b1b-9f51-bbbd44b9b4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
