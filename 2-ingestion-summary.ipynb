{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e296fd-2c54-49d8-92a7-4049f3fa1152",
   "metadata": {},
   "source": [
    "# Data Ingestion Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71c118-6e34-45fc-ba8b-955eeac18d74",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9e985-1042-4810-aabc-089e0c55af95",
   "metadata": {},
   "source": [
    "Over the past several lessons, we have discussed how llama-index can help us with data ingestion.  And so it's useful to recap how that stage works here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeed341-e3b1-448e-af3f-03480fec2a8a",
   "metadata": {},
   "source": [
    "### Moving through the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799fc40-1877-4d0e-b88c-c497290d228f",
   "metadata": {},
   "source": [
    "1. Loading Data with Connectors\n",
    "\n",
    "The first step is loading data with connectors.  Llama-index provides various connectors like: \n",
    "\n",
    "* GoogleDocsReader\n",
    "* SlackReader\n",
    "* SimpleDirectoryReader\n",
    "* UnstructuredReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5eb231-8643-4cd0-8a7d-f7a9e30defd4",
   "metadata": {},
   "source": [
    "And they all work by initializing the connector and then calling the load_data() function to return a list of document objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d4e58-d0ae-49ef-8370-dc2c439967fc",
   "metadata": {},
   "source": [
    "```python\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"http://paulgraham.com/worked.html\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19452c7-8d6f-4283-a1a9-7b2601725cff",
   "metadata": {},
   "source": [
    "> You can see various connectors [here](https://llamahub.ai/) on llamahub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500928c-54fc-45c2-b257-0453d7ae4a12",
   "metadata": {},
   "source": [
    "### Node Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c97c1c-9288-4ac9-bff4-221ec842ef55",
   "metadata": {},
   "source": [
    "Once we have our document objects, the next step is to parse these documents into chunks, which in llama-index are stored in our node objects.  \n",
    "\n",
    "Remember that these node objects can store various information on them like the text, the embedding, the start index from the document, and previous and following chunks (ie nodes).  They can store additional meta-data like the page number from the document, or the earlier's nodes text summary.\n",
    "\n",
    "So how do we turn a document into chunks?  With a parser.  So far we have used the sentence splitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1a615-28bf-4277-a49f-b7ba4f82aaca",
   "metadata": {},
   "source": [
    "```python\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc3378-a467-496e-8a6d-94d079fd37dc",
   "metadata": {},
   "source": [
    "But there are various other parsers.  For example, there are parses for properly chunking HTML, or code, or markdown.  Take a look at some of the other parsers [here](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a9a021-a08e-4fca-9b2b-1d1a611f5809",
   "metadata": {},
   "source": [
    "### Storing and Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbc3ee-6d53-45c3-b484-15d5f046aa96",
   "metadata": {},
   "source": [
    "Once we have the nodes we can store and query our data.  Passing our nodes into an index, will automatically create the embeddings for each node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485f801-f173-4533-aafb-a0d4559e66ad",
   "metadata": {},
   "source": [
    "```python\n",
    "embed_model.get_text_embedding(\n",
    "            node.get_content()\n",
    "        )\n",
    "        node.embedding = node_embedding\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1524b6-cc8d-4923-9f29-a365b9beabda",
   "metadata": {},
   "source": [
    "So we can just write the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430f960-ac6e-4f37-afe7-c1bbcd54e79c",
   "metadata": {},
   "source": [
    "```python\n",
    "index = VectorStoreIndex(nodes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0192fda5-4b21-4ed3-bd5c-7fd854d821bd",
   "metadata": {},
   "source": [
    "Remember, this will, create and store embeddings on each node, create and store the nodes in a vector database, and declare an index which specifies how our nodes are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c51bff-8119-4927-a819-c709b5d7d76d",
   "metadata": {},
   "source": [
    "From there we can create a query engine to query the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ec471-28fb-4ba3-8100-b1a385e46a5b",
   "metadata": {},
   "source": [
    "```python\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is this document about?\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5999673-9ce8-4fe2-9e93-0e2915449725",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c3bab-3ec1-4c22-af84-dafc920cddd0",
   "metadata": {},
   "source": [
    "So we saw that in the data ingestion stage, both connectors and parsing is involved.  Then we store the data and create a query engine to query the data.\n",
    "\n",
    "However, if we want to simply perform all of these steps as quickly as possible (and skip the explicit node parsing stage), we can go from data retrieval to parsing to storage to querying in just a few lines like so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b340e-df90-48b7-8956-2433e3d27933",
   "metadata": {},
   "source": [
    "```python\n",
    "lyft_docs = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(lyft_docs)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is this document about?\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
